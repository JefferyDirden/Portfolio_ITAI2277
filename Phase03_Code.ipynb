{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1P9NqBKROYbWAesdcVb_dT-6-s5BuIbCH","authorship_tag":"ABX9TyMOK8ykJ6kCnJCDsQPagPc0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Phase 3: Scaling CV Prototype for TriagePal\n","This notebook expands the Phase 2 eye classification to include **rashes** (Fitzpatrick17k) and **wounds** (Wound Classification dataset from Kaggle). We use **transfer learning with MobileNetV2** for fine-tuning multi-class CNNs, **data augmentation**, and **class weights** for imbalances. Finally, we test an **integrated pipeline** that processes images from multiple categories.\\n,\n","  \n","   ## Key Features:\n","  - **Eyes**: Binary (healthy vs. infected) from Phase 2.\n","  - **Rashes**: Multi-class (e.g., psoriasis, dermatitis) from Fitzpatrick17k.\n","  - **Wounds**: Multi-class severity (e.g., abrasions, burns) from Kaggle wound dataset.\n","  - **Fine-tuning**: MobileNetV2 base + custom head.\n"," - **Augmentation & Weights**: Built-in via Keras.\n","  - **Integration**: Unified prediction function (select model by image type).\n","  \n","  **Setup**: Upload Kaggle API key (`kaggle.json`) in the first cell. Datasets will auto-download.\n","\n","  ## Next: NLP Integration\n","  After CV, add BERT for symptoms (see comments at end)"],"metadata":{"id":"RWS6H9hgTS5Q"}},{"cell_type":"code","source":["import kagglehub\n","\n","# Download latest version\n","path = kagglehub.dataset_download(\"alisofiya/conjunctivitis\")\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQxq9Ha_hOlF","executionInfo":{"status":"ok","timestamp":1761532510268,"user_tz":300,"elapsed":1394,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"a56af504-508a-4992-aaec-8f8e557a1098"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/alisofiya/conjunctivitis?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 32.5M/32.5M [00:00<00:00, 149MB/s] "]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/alisofiya/conjunctivitis/versions/1\n"]}]},{"cell_type":"code","source":["# Setup Kaggle API (Run once per session),\n","from google.colab import files\n","files.upload()  # Upload kaggle.json\n","!mkdir -p ~/.kaggle/\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets list  # Test API"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"W_Di45SlhsSF","executionInfo":{"status":"ok","timestamp":1761532760412,"user_tz":300,"elapsed":16643,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"b52795a3-f3b4-4c66-f31e-a54f229a67c5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d9909f65-1378-402e-8cee-0f6125e79a2a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d9909f65-1378-402e-8cee-0f6125e79a2a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle (1).json to kaggle (1) (1).json\n","cp: cannot stat 'kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 4, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/__init__.py\", line 6, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 434, in authenticate\n","    raise IOError('Could not find {}. Make sure it\\'s located in'\n","OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"]}]},{"cell_type":"markdown","source":["## Cell 1: Installs & Imports"],"metadata":{"id":"EgGv18ediXXt"}},{"cell_type":"code","source":["!pip install -q kaggle tensorflow matplotlib scikit-learn pandas pillow\n","\n","import os, glob, random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import MobileNetV2\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Reproducibility\n","SEED = 42\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","print(\"TensorFlow version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3H_tzHNGipNC","executionInfo":{"status":"ok","timestamp":1761533182461,"user_tz":300,"elapsed":9643,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"4e92e155-781d-4454-9ccf-2c72cbe992b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.19.0\n"]}]},{"cell_type":"markdown","source":["## Load Datasets\n","        \n","### 1. Eyes (Binary: Healthy vs. Infected)\n","\n"],"metadata":{"id":"capgpmApkCvK"}},{"cell_type":"code","source":["# Download & Load Eyes Dataset\n","!kaggle datasets download -d alisofiya/conjunctivitis -p /content/eyes --unzip\n","eyes_root = Path('/content/eyes/conjunctivitis')\n","img_files_eyes = list(eyes_root.rglob(\"*.jpg\")) + list(eyes_root.rglob(\"*.jpeg\"))\n","rows_eyes = [[str(p.resolve()), p.parent.name] for p in img_files_eyes]\n","df_eyes = pd.DataFrame(rows_eyes, columns=[\"image_path\", \"label\"])\n","df_eyes = df_eyes.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","print(\"Eyes Dataset:\")\n","print(df_eyes['label'].value_counts())\n","print(\"\\nSample:\")\n","display(df_eyes.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"cbbxXmnMkmyc","executionInfo":{"status":"ok","timestamp":1761533781500,"user_tz":300,"elapsed":447,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"3f7a15ba-cc06-434e-8b1e-93e83c9e228a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n","    out = args.func(**command_args)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n","    with self.build_kaggle_client() as kaggle:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n","    username=self.config_values['username'],\n","             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'username'\n","Eyes Dataset:\n","Series([], Name: count, dtype: int64)\n","\n","Sample:\n"]},{"output_type":"display_data","data":{"text/plain":["Empty DataFrame\n","Columns: [image_path, label]\n","Index: []"],"text/html":["\n","  <div id=\"df-491094ca-7c44-40c0-9990-c9ea95aa9a6c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-491094ca-7c44-40c0-9990-c9ea95aa9a6c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-491094ca-7c44-40c0-9990-c9ea95aa9a6c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-491094ca-7c44-40c0-9990-c9ea95aa9a6c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{}}]},{"cell_type":"markdown","source":["### 2. Rashes (Multi-Class: Filtered Fitzpatrick17k)"],"metadata":{"id":"8dI3tlIImj4w"}},{"cell_type":"code","source":["# Download & Load Rashes (Fitzpatrick17k)\n","!kaggle datasets download -d nazmussadat013/fitzpatrick17k -p /content/rashes --unzip\n","\n","rashes_root = Path('/content/fitzpatrick17k.csv')\n","csv_path = rashes_root / 'fitzpatrick17k.csv'\n","images_dir = rashes_root / 'images_part_1'  # Adjust if multi-part; merge if needed\n","\n","if not csv_path.exists():\n","    print(f\"Error: CSV file not found at {csv_path}. Please ensure the Kaggle dataset is downloaded and unzipped correctly.\")\n","else:\n","    df_rashes = pd.read_csv(csv_path)\n","    df_rashes['image_path'] = (images_dir / (df_rashes['md5hash'] + '.jpg')).astype(str)\n","    df_rashes = df_rashes[df_rashes['image_path'].apply(os.path.exists)]  # Filter existing\n","\n","    # Filter for common rash types (customize based on your CSV sample)\n","    rash_types = ['psoriasis', 'acne vulgaris', 'allergic contact dermatitis', 'urticaria', 'lichen planus']\n","    df_rashes = df_rashes[df_rashes['label'].str.contains('|'.join(rash_types), na=False, case=False)]\n","\n","    # Sample for speed (200 per class)\n","    df_rashes = df_rashes.groupby('label').apply(lambda x: x.sample(min(200, len(x)), random_state=SEED)).reset_index(drop=True)\n","\n","    print(\"Rashes Dataset (Sampled):\")\n","    print(df_rashes['label'].value_counts())\n","    print(\"\\nSample:\")\n","    display(df_rashes.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EO8jQUOmlv7","executionInfo":{"status":"ok","timestamp":1761534236800,"user_tz":300,"elapsed":313,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"14dc4733-6e4d-45e4-a6ee-df7b8fe5afa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n","    out = args.func(**command_args)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n","    with self.build_kaggle_client() as kaggle:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n","    username=self.config_values['username'],\n","             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'username'\n","Error: CSV file not found at /content/fitzpatrick17k.csv/fitzpatrick17k.csv. Please ensure the Kaggle dataset is downloaded and unzipped correctly.\n"]}]},{"cell_type":"markdown","source":["### 3. Wounds (Multi-Class: Severity from Kaggle)"],"metadata":{"id":"BUTZTneBn5YB"}},{"cell_type":"code","source":["# Download & Load Wounds Dataset\n","!kaggle datasets download -d ibrahimfateen/wound-classification -p /content/wounds --unzip\n","\n","wounds_root = Path('/content/wounds/Wound_dataset')\n","rows_wounds = []\n","\n","if not wounds_root.exists():\n","    print(f\"Error: Dataset directory not found at {wounds_root}. Please ensure the Kaggle dataset is downloaded and unzipped correctly.\")\n","else:\n","    for label in wounds_root.iterdir():\n","        if label.is_dir():\n","            for img in label.glob('*.jpg'):\n","                rows_wounds.append([str(img.resolve()), label.name])\n","\n","    df_wounds = pd.DataFrame(rows_wounds, columns=[\"image_path\", \"label\"])\n","    df_wounds = df_wounds.sample(frac=1, random_state=SEED).reset_index(drop=True)\n","\n","    # Sample for speed (200 per class)\n","    df_wounds = df_wounds.groupby('label').apply(lambda x: x.sample(min(200, len(x)), random_state=SEED)).reset_index(drop=True)\n","\n","    print(\"Wounds Dataset (Sampled):\")\n","    print(df_wounds['label'].value_counts())\n","    print(\"\\nSample:\")\n","    display(df_wounds.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NReGEsgEoAMh","executionInfo":{"status":"ok","timestamp":1761534467226,"user_tz":300,"elapsed":424,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"67c36a1d-d0e4-4dbb-e532-6f320ab4a40a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n","    out = args.func(**command_args)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n","    with self.build_kaggle_client() as kaggle:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n","    username=self.config_values['username'],\n","             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'username'\n","Error: Dataset directory not found at /content/wounds/Wound_dataset. Please ensure the Kaggle dataset is downloaded and unzipped correctly.\n"]}]},{"cell_type":"markdown","source":["## Prepare Data: Splits, Generators, Weights"],"metadata":{"id":"e9NOPG0-o2gT"}},{"cell_type":"code","source":["IMG_SIZE = (224, 224)  # MobileNetV2 default\n","BATCH_SIZE = 32\n","# Common Augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Function to prepare splits & generators\n","def prepare_data(df, class_mode='binary', val_size=0.2, test_size=0.1):\n","    train_df, temp_df = train_test_split(df, test_size=val_size + test_size, stratify=df['label'], random_state=SEED)\n","    val_df, test_df = train_test_split(temp_df, test_size=test_size/(val_size + test_size), stratify=temp_df['label'], random_state=SEED)\n","\n","    train_gen = train_datagen.flow_from_dataframe(train_df, x_col='image_path', y_col='label', target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=class_mode, shuffle=True)\n","    val_gen = val_datagen.flow_from_dataframe(val_df, x_col='image_path', y_col='label', target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=class_mode, shuffle=False)\n","    test_gen = val_datagen.flow_from_dataframe(test_df, x_col='image_path', y_col='label', target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=class_mode, shuffle=False)\n","\n","    # Class weights for imbalance\n","    classes = np.unique(df['label'])\n","    class_weights = compute_class_weight('balanced', classes=classes, y=df['label'])\n","    class_weight_dict = dict(zip(classes, class_weights))\n","\n","    return train_gen, val_gen, test_gen, class_weight_dict, test_df\n","\n","# Prepare for each\n","train_gen_eyes, val_gen_eyes, test_gen_eyes, weights_eyes, test_df_eyes = prepare_data(df_eyes, 'binary')\n","train_gen_rashes, val_gen_rashes, test_gen_rashes, weights_rashes, test_df_rashes = prepare_data(df_rashes, 'categorical')\n","train_gen_wounds, val_gen_wounds, test_gen_wounds, weights_wounds, test_df_wounds = prepare_data(df_wounds, 'categorical')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"FhsggMslo8mp","executionInfo":{"status":"error","timestamp":1761534902789,"user_tz":300,"elapsed":58,"user":{"displayName":"Jazmine","userId":"04718938192117862694"}},"outputId":"97b5fed0-30e8-42f4-baab-5614687ca75e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3551741580.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Prepare for each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_gen_eyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen_eyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen_eyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_eyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_eyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_eyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mtrain_gen_rashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen_rashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen_rashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_rashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_rashes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'categorical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtrain_gen_wounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gen_wounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gen_wounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_wounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_wounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_wounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'categorical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3551741580.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(df, class_mode, val_size, test_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Function to prepare splits & generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}]},{"cell_type":"markdown","source":["###Fine-Tune Models with MobileNetV2"],"metadata":{"id":"xQrLfDmVN5Fo"}},{"cell_type":"code","source":[],"metadata":{"id":"iuw78akmN9IO"},"execution_count":null,"outputs":[]}]}